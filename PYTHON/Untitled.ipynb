{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Running simulation only on the following countries:\n",
      "392\n",
      "764\n",
      "496\n",
      "144\n",
      "524\n",
      "Reading Numpy arrays\n"
     ]
    }
   ],
   "source": [
    "import os, datetime, sys, operator, logging, math, csv, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "print('Starting')\n",
    "\n",
    "\n",
    "# Turns a list of dictionaries into a single one:\n",
    "def transposeDict(listOfDicts, pk):\n",
    "    output = {}\n",
    "    for dic in listOfDicts:\n",
    "        output[dic[pk]] = dic\n",
    "    return output\n",
    "\n",
    "\n",
    "os.chdir(os.path.expanduser('~') + '/Dropbox/CISC - Global Population/Asia/');\n",
    "\n",
    "\n",
    "\n",
    "# This will get rid of some floating point issues (well, reporting of them!)\n",
    "old_settings = np.seterr(invalid=\"ignore\")\n",
    "\n",
    "# run the simulation only on specific countries, or on all countries found in the input files?\n",
    "# runCountries = \"all\"\n",
    "runCountries = [\"392\", \"764\", \"496\", \"144\", \"524\"] # look up the country codes in the WUP or WTP csv files; make sure to put in quotes!\n",
    "\n",
    "WTP = transposeDict(csv.DictReader(open('WTP2014_Asia.csv')), \"Country Code\")\n",
    "\n",
    "urbanCell = 2\n",
    "ruralCell = 1\n",
    "MAJ = 'Major area, region, country or area'\n",
    "\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "# if we are running on all countries, make an array that contains all country IDs from WTP top iterate over later:\n",
    "if(runCountries == \"all\"):\n",
    "    print('Running simulation on all countries.')\n",
    "    runCountries = []\n",
    "    for country in WTP:\n",
    "        runCountries.append(country)\n",
    "else:\n",
    "    print('Running simulation only on the following countries:')\n",
    "    for country in runCountries:\n",
    "        print(country)\n",
    "\n",
    "print('Reading Numpy arrays')\n",
    "\n",
    "# in this dataset: 1=rural, 2=urban\n",
    "# we flatten (\"ravel\") all arrays to 1D, so we don't have to deal with 2D arrays:\n",
    "urbanRural = np.load('GLUR_asia.tif.npy').ravel()\n",
    "\n",
    "countryBoundaries = np.load('Nations_Asia.tif.npy').ravel()\n",
    "\n",
    "# load population raster datasets for 2010\n",
    "pop2010 = np.load('Population_2010_Asia.tif.npy').ravel()\n",
    "\n",
    "# these arrays use very small negative numbers as NULL,\n",
    "# let's convert these to NAN\n",
    "pop2010[pop2010==np.nanmin(pop2010)] = np.nan\n",
    "\n",
    "# make an array of all indexes; we'll use this later:\n",
    "allIndexes = np.arange(countryBoundaries.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Japan\n",
      "Processing Thailand\n",
      "Processing Mongolia\n",
      "Processing Sri Lanka\n",
      "Processing Nepal\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# this part is tricky: split up the number of countries into an nXn grid (roughly), then use those as subplots: \n",
    "dim = np.ceil(np.sqrt(len(runCountries)))\n",
    "subplots = np.array_split(runCountries, dim)\n",
    "f, subplots = pyplot.subplots(len(subplots), len(subplots[0]), sharex='col', sharey='row')\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "for country in runCountries:\n",
    "    \n",
    "    c = WTP[str(country)][MAJ]\n",
    "    print 'Processing '+c\n",
    "\n",
    "    \n",
    "    # fetch the urban and rural cells for the current country:\n",
    "    u = pop2010[\n",
    "        np.logical_and(countryBoundaries == int(country),\n",
    "                       urbanRural == urbanCell)]\n",
    "\n",
    "    # sub-array with rural pop numbers for current country\n",
    "    r = pop2010[\n",
    "        np.logical_and(countryBoundaries == int(country),\n",
    "                       urbanRural == ruralCell)]\n",
    "\n",
    "    # then chuck the histograms into the next subplot:\n",
    "    subplots[i][j].hist(np.log(r+1), normed=True, bins=100, alpha=0.5, label='Rural')\n",
    "    subplots[i][j].hist(np.log(u+1), normed=True, bins=100, alpha=0.5, label='Urban')\n",
    "    subplots[i][j].set_title(c)\n",
    "    \n",
    "    if i == dim-1:\n",
    "        i = 0\n",
    "        j = j + 1\n",
    "    else:\n",
    "        i = i + 1\n",
    "        \n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.savefig(os.path.expanduser('~') + '/Dropbox/Code/CISC/PYTHON/histograms/_hist-facets.pdf', bbox_inches='tight')\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Japan\n",
      "Processing Thailand\n",
      "Done.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
